{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaneamento de documento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Usaremos o código da pasta '1.introduction' para tranformação de perspectiva usando 4 pontos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordenação dos quatro pontos de um documento (as bordas);\n",
    "# esquerda-superior, direita-superior, direita-inferior e esquerda-inferior.\n",
    "def order_points(pts):\n",
    "    # inicializar a lista de coordenadas que serão ordenadas\n",
    "    # ordem: superior-esquerdo, superior-direito, inferior-direito, inferior-esquerdo\n",
    "    # np.zeros => ((nº linhas, nº colunas), tipo_variavel)\n",
    "    rect = np.zeros((4,2), dtype='float32')\n",
    "    \n",
    "    # o ponto superior esquerdo terá a menor soma, enquanto\n",
    "    # o ponto inferior direito terá a maior soma\n",
    "    s = pts.sum(axis=1) # soma por linha\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "    \n",
    "    # calcula a diferença entre os pontos\n",
    "    # o canto superior direito terá uma diferença menor\n",
    "    # o canto inferior esquerdo terá uma diferença maior\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    \n",
    "    # retorna as coordenadas ordenadas\n",
    "    return rect\n",
    "\n",
    "# gera as quatro bordas da imagem, cálculo feito com base nas maiores distâncias entre pontos.\n",
    "def four_point_tranform(image, pts):\n",
    "    # obtem os pontos ordenados no formato correto\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "    \n",
    "    # calcula a maior largura da imagem com base nos pontos (coordenada X)\n",
    "    # distância entre o br e bl\n",
    "    # distância entre o tr e tl\n",
    "    # calcula a maior distância\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "    \n",
    "    # calcula a maior altura da imagem com base nos pontos (coordenada Y)\n",
    "    # distância entre tr e br\n",
    "    # distância entre tl e bl\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "    \n",
    "    # agora que temos as dimenções da nova imagem\n",
    "    # construimos os pontos para obter a vista de 'cima' (vista desejada)\n",
    "    # seguindo a ordem dos pontos: tl, tr, br, bl\n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [maxWidth - 1, 0],\n",
    "        [maxWidth - 1, maxHeight - 1],\n",
    "        [0, maxHeight - 1]], dtype = 'float32')\n",
    "    \n",
    "    # calcula a matriz de transformação de perspectiva\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    # aplica a matriz de transformação de perspectiva\n",
    "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "    \n",
    "    # retorna a imagem distorcida\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import threshold_local\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carregando imagem e detecção de borda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Carregando a imagem e redimensionando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregue a imagem e calcule a proporção da altura antiga\n",
    "# à nova altura, clone-a e redimensione-a\n",
    "loc_image = \"./images/receipt.jpg\"\n",
    "image = cv2.imread(loc_image)\n",
    "\n",
    "# técnica utilizada para aumentar a acurácia\n",
    "ratio = image.shape[0] / 500\n",
    "orig = image.copy()\n",
    "image = imutils.resize(image, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Convertendo cor e detecção de borda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converte a imagem em tons de cinza\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# execute a desfocagem gaussiana para remover o ruído \n",
    "# de alta frequência (auxiliando na detecção de contorno na Etapa 2)\n",
    "gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "# e execute a detecção de borda Canny\n",
    "edged = cv2.Canny(gray, 75, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 Visualizando resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualização da imagem original e a detecção de borda\n",
    "\n",
    "cv2.imshow(\"Imagem\", image)\n",
    "cv2.imshow(\"Edged\", edged)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Encontrando contornos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Detectando contornos e retornando os maiores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encontre os contornos na imagem com arestas, mantendo apenas\n",
    "# maiores e inicializar o contorno da tela\n",
    "cnts = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "cnts = sorted(cnts, key = cv2.contourArea, reverse = True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Encontrando contorno com 4 pontos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop para cada contorno encontrado\n",
    "for c in cnts:\n",
    "    # aproximar o contorno\n",
    "    peri = cv2.arcLength(c, True)\n",
    "    \n",
    "    # aproximar numero de ponto\n",
    "    approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "    \n",
    "    # se o contorno tiver 4 pontos, assumimos que encontramos\n",
    "    if len(approx) == 4:\n",
    "        screenCut = approx\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Visualizando resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizando o contorno\n",
    "\n",
    "cv2.drawContours(image, [screenCut], -1, (0,255,0), 2)\n",
    "cv2.imshow(\"Outline\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Aplicar uma transformação de perspectiva e um limite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[241, 142],\n",
       "       [ 82, 151],\n",
       "       [103, 414],\n",
       "       [281, 388]], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "screenCut.reshape(4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicando a transformação de quatro pontos para obter a vista top-down da imagem original\n",
    "warped = four_point_tranform(orig, screenCut.reshape(4, 2) * ratio) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converted a imagem deformada em tons de cinza e encontra os limites da imagem\n",
    "# transforma a imagem em tons de cinza\n",
    "warped = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# calculo do limite\n",
    "T = threshold_local(warped, 11, offset = 10, method = \"gaussian\")\n",
    "\n",
    "# aplica o limite a imagem deformada\n",
    "warped = (warped > T).astype(\"uint8\") * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizando resultado\n",
    "cv2.imshow(\"Original\", imutils.resize(orig, height = 650))\n",
    "cv2.imshow(\"Scanned\", imutils.resize(warped, height = 650))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
